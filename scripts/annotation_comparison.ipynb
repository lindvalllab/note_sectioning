{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "from environs import Env\n",
    "sys.path.append('../')\n",
    "from src.labelprocessor import LabelProcessor\n",
    "from src.errorlogger import ErrorLogger\n",
    "from src.pdfgenerator import PDFGenerator\n",
    "from utils.loader import load_data\n",
    "from utils.annotation_analysis import annotation_overview_text, annotation_overview_plot\n",
    "\n",
    "env = Env()\n",
    "env.read_env('../.env')\n",
    "study_path = env(\"STUDY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"GI\" # Breast, GI, Neuro\n",
    "studies_folder = f\"{study_path}/{type}/CSV/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Processor for computing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_df, k_df = load_data(studies_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process labels and calculate accuracy\n",
    "processor = LabelProcessor(k_df, j_df)\n",
    "result_df = processor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df['HPI_Interval_Hx'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df['A&P'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Logger for error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_logger = ErrorLogger(result_df)\n",
    "# error_logger.log_errors(f\"../outputs/{type}_conflicts_log.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = PDFGenerator(k_df, j_df, result_df)\n",
    "generator.convert_to_pdf(f\"../outputs/{type}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = error_logger.get_error_df()\n",
    "filtered_k_df = k_df.loc[error_df.index]\n",
    "filtered_j_df = j_df.loc[error_df.index]\n",
    "generator_error = PDFGenerator(filtered_k_df, filtered_j_df, error_df)\n",
    "generator_error.convert_to_pdf(f\"../outputs/{type}_conflicts.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_overview_text(result_df, 0.8, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_overview_plot(result_df, 0.8, type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating adjudication batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = pd.read_csv(f'{study_path}/notes_to_annotate/{type}/{type}_batch_1.csv')\n",
    "def create_subdataframe(result_df, j_df, reference, threshold):\n",
    "    merged_df = j_df.join(result_df[['HPI_Interval_Hx', 'A&P']], how='inner')\n",
    "    mask = (merged_df['HPI_Interval_Hx'] < threshold) | (merged_df['A&P'] < threshold)\n",
    "    sub_df = merged_df[mask].copy()\n",
    "    columns_to_keep = reference.columns.tolist() + ['HPI_Interval_Hx', 'A&P']\n",
    "    sub_df = sub_df[columns_to_keep]\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = create_subdataframe(result_df, j_df, reference, threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv_in_batches(df, type, batch_size=25):\n",
    "    num_batches = math.ceil(len(df) / batch_size)\n",
    "    for i in range(num_batches):\n",
    "        batch_df = df.iloc[i * batch_size : (i + 1) * batch_size]\n",
    "        file_name = f\"../outputs/adjudication/{type}/{type}_batch_{i + 1}.csv\"\n",
    "        batch_df.to_csv(file_name, index=False)\n",
    "        error_logger = ErrorLogger(batch_df)\n",
    "        error_df = error_logger.get_error_df()\n",
    "        filtered_k_df = k_df.loc[error_df.index]\n",
    "        filtered_j_df = j_df.loc[error_df.index]\n",
    "        generator_error = PDFGenerator(filtered_k_df, filtered_j_df, error_df)\n",
    "        generator_error.convert_to_pdf(f\"../outputs/adjudication/{type}/{type}_batch_{i + 1}.pdf\")\n",
    "        print(f\"Saved: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv_in_batches(sub_df, type, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "gt_df = processor.generate_gt()\n",
    "\n",
    "def extract_labels(df):\n",
    "    hpi_texts = []\n",
    "    ap_texts = []\n",
    "    \n",
    "    for row in df['k_label']:\n",
    "        if pd.notna(row):\n",
    "            try:\n",
    "                label_data = json.loads(row)\n",
    "                hpi_text = None\n",
    "                ap_text = None\n",
    "                for item in label_data:\n",
    "                    text = item['text']\n",
    "                    label = item['labels'][0]  # We assume there's only one label in the list\n",
    "                    if label == \"HPI_Interval_Hx\":\n",
    "                        hpi_text = text\n",
    "                    elif label == \"A&P\":\n",
    "                        ap_text = text\n",
    "                hpi_texts.append(hpi_text)\n",
    "                ap_texts.append(ap_text)\n",
    "            except json.JSONDecodeError:\n",
    "                hpi_texts.append(None)\n",
    "                ap_texts.append(None)\n",
    "        else:\n",
    "            hpi_texts.append(None)\n",
    "            ap_texts.append(None)\n",
    "    new_df = pd.DataFrame({\n",
    "        'HPI_Interval_Hx': hpi_texts,\n",
    "        'A&P': ap_texts\n",
    "    })\n",
    "    return new_df\n",
    "\n",
    "new_df = extract_labels(gt_df)\n",
    "\n",
    "new_df = j_df.join(new_df[['HPI_Interval_Hx', 'A&P']], how='inner')\n",
    "columns_to_keep = reference.columns.tolist() + ['HPI_Interval_Hx', 'A&P']\n",
    "new_df = new_df[columns_to_keep]\n",
    "\n",
    "new_df.to_csv(f\"../outputs/gt/{type}_gt.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notesectioning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
