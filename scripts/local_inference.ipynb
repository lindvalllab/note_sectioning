{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from environs import Env\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.labelprocessor import LabelProcessor\n",
    "from utils.loader import load_data\n",
    "from utils.structs import IntervalHistoryOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"GI\"\n",
    "studies_folder = f\"../data/{type}/CSV/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_df, k_df = load_data(studies_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process labels and calculate accuracy\n",
    "processor = LabelProcessor(k_df, j_df)\n",
    "result_df = processor.process()\n",
    "# Keep only the samples without conflict and rearrange data\n",
    "gt_df = processor.generate_gt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt = \"\"\"You are a helpful assistant with a strong clinical background in oncology. \n",
    "You know that medical notes are generally organized in sections, and your task is to find \n",
    "the part of the note corresponding to the section containing the History of present illness and \n",
    "the Interval history. You should organize this information in a json file that will contain a \n",
    "dictionary with two keys: HPI_Interval_Hx_begin, and HPI_Interval_Hx_end. HPI_Interval_Hx_begin \n",
    "should contain the 5 first words of the HPI_Interval_Hx section, and HPI_Interval_Hx_end should \n",
    "contain the last 5 words of the HPI_Interval_Hx section.  Here is the medical note: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hpi_intervals(df):\n",
    "    hpi_begin = []\n",
    "    hpi_end = []\n",
    "    for note in tqdm(df['note_text'], desc=\"Processing Notes\"):\n",
    "        prompt = main_prompt + note\n",
    "        payload = {\n",
    "            \"prompt\": prompt,\n",
    "        }\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        try:\n",
    "            url = \"http://localhost:8080/completion\"\n",
    "            response = requests.post(url, json=payload, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json().get('content', None)\n",
    "            if result:\n",
    "                # print(f\"Result content: {result}\")\n",
    "                result_dict = json.loads(result)\n",
    "                hpi_begin_text = result_dict.get('HPI_Interval_Hx_begin', None)\n",
    "                hpi_end_text = result_dict.get('HPI_Interval_Hx_end', None)\n",
    "                if hpi_begin_text:\n",
    "                    begin_words = hpi_begin_text.split()\n",
    "                    hpi_begin.append(' '.join(begin_words[:5]))\n",
    "                else:\n",
    "                    hpi_begin.append(None)\n",
    "                if hpi_end_text:\n",
    "                    end_words = hpi_end_text.split()\n",
    "                    hpi_end.append(' '.join(end_words[:5]))\n",
    "                else:\n",
    "                    hpi_end.append(None)\n",
    "            else:\n",
    "                hpi_begin.append(None)\n",
    "                hpi_end.append(None)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            hpi_begin.append(None)\n",
    "            hpi_end.append(None)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Decode Error: {e}\")\n",
    "            hpi_begin.append(None)\n",
    "            hpi_end.append(None)\n",
    "    df['start_pred_string'] = hpi_begin\n",
    "    df['end_pred_string'] = hpi_end\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = generate_hpi_intervals(gt_df)\n",
    "updated_df.to_csv(f\"../outputs/local_llm/{type}/8192/llama_3_1_8B_Q4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(f\"../outputs/local_llm/{type}/8192/llama_3_1_8B_Q6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = processor.reorganize_outputs(updated_df, IntervalHistoryOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted function to take 'note', 'start', and 'end' from the same DataFrame row with optional fuzzy matching\n",
    "def extract_section_from_note_from_row(row, use_fuzzy: bool = False, fuzz_threshold: int = 80) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extracts a section from a clinical note given the start and end strings from the same DataFrame row,\n",
    "    with optional fuzzy matching.\n",
    "\n",
    "    :param row: A row from a DataFrame containing 'note_text', 'start', and 'end' columns.\n",
    "    :param use_fuzzy: Boolean flag to enable fuzzy matching.\n",
    "    :param fuzz_threshold: The minimum similarity score for fuzzy matching (0-100).\n",
    "    :return: The extracted section text, or None if the section cannot be found.\n",
    "    \"\"\"\n",
    "    note = row['note']\n",
    "    start_string = row['start_pred_string']\n",
    "    end_string = row['end_pred_string']\n",
    "    \n",
    "    if pd.isna(start_string) or pd.isna(end_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    if use_fuzzy:\n",
    "        # Perform fuzzy matching for start_string\n",
    "        start_match = process.extractOne(start_string, note.splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "        if start_match:\n",
    "            start_string = start_match[0]\n",
    "        \n",
    "        # Perform fuzzy matching for end_string\n",
    "        end_match = process.extractOne(end_string, note.splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "        if end_match:\n",
    "            end_string = end_match[0]\n",
    "\n",
    "    if start_string not in note or end_string not in note:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    start_index = note.find(start_string)\n",
    "    end_index = note.find(end_string, start_index) + len(end_string)\n",
    "\n",
    "    if start_index == -1 or end_index == -1 or start_index >= end_index:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row in the DataFrame with fuzzy matching enabled\n",
    "gt_df['start_pred_strict'], gt_df['end_pred_strict'] = zip(*gt_df.apply(lambda row: extract_section_from_note_from_row(row, use_fuzzy=False, fuzz_threshold=70), axis=1))\n",
    "gt_df['start_pred_fuzzy'], gt_df['end_pred_fuzzy'] = zip(*gt_df.apply(lambda row: extract_section_from_note_from_row(row, use_fuzzy=True, fuzz_threshold=70), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(df, start_col, end_col, start_pred_col, end_pred_col):\n",
    "    def calc_metrics(row):\n",
    "        gt_start, gt_end = row[start_col], row[end_col]\n",
    "        pred_start, pred_end = row[start_pred_col], row[end_pred_col]\n",
    "        em = int(gt_start == pred_start and gt_end == pred_end)\n",
    "        intersection = max(0, min(gt_end, pred_end) - max(gt_start, pred_start) + 1)\n",
    "        pred_len = pred_end - pred_start + 1\n",
    "        gt_len = gt_end - gt_start + 1\n",
    "        precision = intersection / pred_len if pred_len > 0 else 0\n",
    "        recall = intersection / gt_len if gt_len > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return pd.Series([em, precision, recall, f1_score], index=['EM', 'Precision', 'Recall', 'F1_Score'])\n",
    "\n",
    "    result_df = df[[start_col, end_col, start_pred_col, end_pred_col]].copy()\n",
    "    result_df[['EM', 'Precision', 'Recall', 'F1_Score']] = df.apply(calc_metrics, axis=1)\n",
    "    return result_df\n",
    "\n",
    "# Apply to both strict and fuzzy\n",
    "strict_df = compute_metrics(gt_df, 'start', 'end', 'start_pred_strict', 'end_pred_strict')\n",
    "fuzzy_df = compute_metrics(gt_df, 'start', 'end', 'start_pred_fuzzy', 'end_pred_fuzzy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for both strict and fuzzy predictions in table format\n",
    "def create_summary(df, label):\n",
    "    summary = df[['EM', 'Precision', 'Recall', 'F1_Score']].mean().reset_index()\n",
    "    summary.columns = ['Metric', label]\n",
    "    return summary\n",
    "\n",
    "# Create summaries for strict and fuzzy\n",
    "strict_summary = create_summary(strict_df, 'Strict')\n",
    "fuzzy_summary = create_summary(fuzzy_df, 'Fuzzy')\n",
    "\n",
    "# Merge and display both summaries side by side in table format\n",
    "summary_table = pd.merge(strict_summary, fuzzy_summary, on='Metric')\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where any of the metrics is zero\n",
    "non_zero_strict = strict_df[(strict_df['Precision'] != 0) & (strict_df['Recall'] != 0) & (strict_df['F1_Score'] != 0)]\n",
    "non_zero_fuzzy = fuzzy_df[(fuzzy_df['Precision'] != 0) & (fuzzy_df['Recall'] != 0) & (fuzzy_df['F1_Score'] != 0)]\n",
    "\n",
    "print(len(non_zero_strict)/len(gt_df), len(non_zero_fuzzy)/len(gt_df))\n",
    "\n",
    "# Create summaries for strict and fuzzy\n",
    "strict_summary = create_summary(non_zero_strict, 'Strict')\n",
    "fuzzy_summary = create_summary(non_zero_fuzzy, 'Fuzzy')\n",
    "\n",
    "# Merge and display both summaries side by side in table format\n",
    "summary_table = pd.merge(strict_summary, fuzzy_summary, on='Metric')\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
