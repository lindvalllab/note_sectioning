{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from environs import Env\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.labelprocessor import LabelProcessor\n",
    "from utils.loader import load_data\n",
    "\n",
    "env = Env()\n",
    "env.read_env('../.env')\n",
    "study_path = env(\"STUDY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"GI\"\n",
    "studies_folder = f\"{study_path}/{type}/CSV/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_df, k_df = load_data(studies_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process labels and calculate accuracy\n",
    "processor = LabelProcessor(k_df, j_df)\n",
    "result_df = processor.process()\n",
    "# Keep only the samples without conflict and rearrange data\n",
    "gt_df = processor.generate_gt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"gpt-4o-mini-2024-07-18-api\"\n",
    "api_version = \"2023-05-15\"\n",
    "endpoint = env(\"ENDPOINT\")\n",
    "entra_scope = env(\"ENTRA_SCOPE\")\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \n",
    "    entra_scope\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntervalHistoryOutput(BaseModel):\n",
    "    start_string: Optional[str] = None\n",
    "    end_string: Optional[str] = None\n",
    "\n",
    "tools = [openai.pydantic_function_tool(IntervalHistoryOutput)]\n",
    "print(tools)\n",
    "\n",
    "def remove_strict_field(data):\n",
    "    # Iterate through each dictionary in the list\n",
    "    for item in data:\n",
    "        # Check if 'strict' is a key in the 'function' dictionary\n",
    "        if 'strict' in item['function']:\n",
    "            # Remove the 'strict' field\n",
    "            del item['function']['strict']\n",
    "    return data\n",
    "\n",
    "def extract_name_value(data):\n",
    "    # Access the 'name' field in the 'function' dictionary\n",
    "    name_value = data[0]['function']['name']\n",
    "    return name_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_chat_completion_response(prompt, input_text):\n",
    "#improve input of schema\n",
    "    schema= [openai.pydantic_function_tool(IntervalHistoryOutput)]\n",
    "    schema=remove_strict_field(schema)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "           \n",
    "        #do not change temperature all research in lab uses temp of 0 unless otherwise discussed\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": input_text}\n",
    "      ],\n",
    "        tools=schema,\n",
    "        tool_choice={\"type\": \"function\", \"function\": {\"name\": f\"{extract_name_value(schema)}\"}},\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.tool_calls[0].function.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"You are a helpful clinical researcher. Your task is to identify the 'Interval History' section in clinical notes provide the first and last 5 words in the Interval History section. if no Interval History output None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = gt_df['note_text'].iloc[2]\n",
    "# print(openai_chat_completion_response(prompt,input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_data(df, prompt, text_column, new_col):\n",
    "    \"\"\"\n",
    "    Process text data in the specified column of the DataFrame using an API call.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing the text data.\n",
    "    text_column (str): Column name in DataFrame that contains the text data to process.\n",
    "    new_col (str): Column name for storing the API responses.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with the new column containing API responses.\n",
    "    \"\"\"\n",
    "    \n",
    "    chunks = df[text_column].tolist()\n",
    "    responses = []  # List to hold the responses\n",
    "\n",
    "    for input_text in tqdm(chunks, desc=\"Processing text data\"):\n",
    "        try:\n",
    "            # Call the API function for each prompt\n",
    "            response = openai_chat_completion_response(prompt,input_text)\n",
    "            responses.append(response)  # Append the response to the list\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with text '{input_text}': {e}\")\n",
    "            responses.append(None)  # Append None in case of an error\n",
    "\n",
    "    # After the loop, responses will have the same order as chunks\n",
    "    df[new_col] = responses  # Assign responses to the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column='note_text'\n",
    "output_column_name='gpt_hx'\n",
    "subgt_df = gt_df.iloc[0:30].copy(deep=True)\n",
    "outputs_df = process_text_data(subgt_df,prompt,input_column,output_column_name)\n",
    "outputs_df.to_json('../outputs/gpt_outputs.json', orient='records')\n",
    "\n",
    "outputs_df = pd.read_json(\"../outputs/gpt_outputs.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = processor.reorganize_outputs(outputs_df, IntervalHistoryOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted function to take 'note', 'start', and 'end' from the same DataFrame row with optional fuzzy matching\n",
    "def extract_section_from_note_from_row(row, use_fuzzy: bool = False, fuzz_threshold: int = 80) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extracts a section from a clinical note given the start and end strings from the same DataFrame row,\n",
    "    with optional fuzzy matching.\n",
    "\n",
    "    :param row: A row from a DataFrame containing 'note_text', 'start', and 'end' columns.\n",
    "    :param use_fuzzy: Boolean flag to enable fuzzy matching.\n",
    "    :param fuzz_threshold: The minimum similarity score for fuzzy matching (0-100).\n",
    "    :return: The extracted section text, or None if the section cannot be found.\n",
    "    \"\"\"\n",
    "    note = row['note']\n",
    "    start_string = row['start_pred_string']\n",
    "    end_string = row['end_pred_string']\n",
    "    \n",
    "    if pd.isna(start_string) or pd.isna(end_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    if use_fuzzy:\n",
    "        # Perform fuzzy matching for start_string\n",
    "        start_match = process.extractOne(start_string, note.splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "        if start_match:\n",
    "            start_string = start_match[0]\n",
    "        \n",
    "        # Perform fuzzy matching for end_string\n",
    "        end_match = process.extractOne(end_string, note.splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "        if end_match:\n",
    "            end_string = end_match[0]\n",
    "\n",
    "    if start_string not in note or end_string not in note:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    start_index = note.find(start_string)\n",
    "    end_index = note.find(end_string, start_index) + len(end_string)\n",
    "\n",
    "    if start_index == -1 or end_index == -1 or start_index >= end_index:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row in the DataFrame with fuzzy matching enabled\n",
    "gt_df['start_pred_strict'], gt_df['end_pred_strict'] = zip(*gt_df.apply(lambda row: extract_section_from_note_from_row(row, use_fuzzy=False, fuzz_threshold=70), axis=1))\n",
    "gt_df['start_pred_fuzzy'], gt_df['end_pred_fuzzy'] = zip(*gt_df.apply(lambda row: extract_section_from_note_from_row(row, use_fuzzy=True, fuzz_threshold=70), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(df, start_col, end_col, start_pred_col, end_pred_col):\n",
    "    def calc_metrics(row):\n",
    "        gt_start, gt_end = row[start_col], row[end_col]\n",
    "        pred_start, pred_end = row[start_pred_col], row[end_pred_col]\n",
    "        em = int(gt_start == pred_start and gt_end == pred_end)\n",
    "        intersection = max(0, min(gt_end, pred_end) - max(gt_start, pred_start) + 1)\n",
    "        pred_len = pred_end - pred_start + 1\n",
    "        gt_len = gt_end - gt_start + 1\n",
    "        precision = intersection / pred_len if pred_len > 0 else 0\n",
    "        recall = intersection / gt_len if gt_len > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return pd.Series([em, precision, recall, f1_score], index=['EM', 'Precision', 'Recall', 'F1_Score'])\n",
    "\n",
    "    result_df = df[[start_col, end_col, start_pred_col, end_pred_col]].copy()\n",
    "    result_df[['EM', 'Precision', 'Recall', 'F1_Score']] = df.apply(calc_metrics, axis=1)\n",
    "    return result_df\n",
    "\n",
    "# Apply to both strict and fuzzy\n",
    "strict_df = compute_metrics(gt_df, 'start', 'end', 'start_pred_strict', 'end_pred_strict')\n",
    "fuzzy_df = compute_metrics(gt_df, 'start', 'end', 'start_pred_fuzzy', 'end_pred_fuzzy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for both strict and fuzzy predictions in table format\n",
    "def create_summary(df, label):\n",
    "    summary = df[['EM', 'Precision', 'Recall', 'F1_Score']].mean().reset_index()\n",
    "    summary.columns = ['Metric', label]\n",
    "    return summary\n",
    "\n",
    "# Create summaries for strict and fuzzy\n",
    "strict_summary = create_summary(strict_df, 'Strict')\n",
    "fuzzy_summary = create_summary(fuzzy_df, 'Fuzzy')\n",
    "\n",
    "# Merge and display both summaries side by side in table format\n",
    "summary_table = pd.merge(strict_summary, fuzzy_summary, on='Metric')\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where any of the metrics is zero\n",
    "non_zero_strict = strict_df[(strict_df['Precision'] != 0) & (strict_df['Recall'] != 0) & (strict_df['F1_Score'] != 0)]\n",
    "non_zero_fuzzy = fuzzy_df[(fuzzy_df['Precision'] != 0) & (fuzzy_df['Recall'] != 0) & (fuzzy_df['F1_Score'] != 0)]\n",
    "\n",
    "print(len(non_zero_strict)/len(gt_df), len(non_zero_fuzzy)/len(gt_df))\n",
    "\n",
    "# Create summaries for strict and fuzzy\n",
    "strict_summary = create_summary(non_zero_strict, 'Strict')\n",
    "fuzzy_summary = create_summary(non_zero_fuzzy, 'Fuzzy')\n",
    "\n",
    "# Merge and display both summaries side by side in table format\n",
    "summary_table = pd.merge(strict_summary, fuzzy_summary, on='Metric')\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "def token_counter(text):\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "# Function to compute the total ratio\n",
    "def compute_total_token_ratio(df):\n",
    "    # Total tokens for the entire 'note' column\n",
    "    total_full_tokens = df['note'].apply(token_counter).sum()\n",
    "\n",
    "    # Total tokens for the substring between start_pred_fuzzy and end_pred_fuzzy\n",
    "    total_fuzzy_tokens = df.apply(lambda row: token_counter(row['note'][row['start_pred_fuzzy']:row['end_pred_fuzzy']]), axis=1).sum()\n",
    "\n",
    "    # Return the ratio of fuzzy tokens to full note tokens\n",
    "    return total_fuzzy_tokens / total_full_tokens if total_full_tokens > 0 else 0\n",
    "\n",
    "# Example usage\n",
    "total_ratio = compute_total_token_ratio(gt_df)\n",
    "print(f\"Total token ratio (fuzzy vs full note): {total_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing Rapid Fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = 1000000\n",
    "\n",
    "import timeit\n",
    "\n",
    "def extract_section_from_note_from_row(row, use_fuzzy: bool = False, fuzz_threshold: int = 80) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extracts a section from a clinical note given the start and end strings from the same DataFrame row,\n",
    "    with optional fuzzy matching.\n",
    "\n",
    "    :param row: A row from a DataFrame containing 'note_text', 'start', and 'end' columns.\n",
    "    :param use_fuzzy: Boolean flag to enable fuzzy matching.\n",
    "    :param fuzz_threshold: The minimum similarity score for fuzzy matching (0-100).\n",
    "    :return: The extracted section text, or None if the section cannot be found.\n",
    "    \"\"\"\n",
    "    note = row['note']\n",
    "    start_string = row['start_pred_string']\n",
    "    end_string = row['end_pred_string']\n",
    "    \n",
    "    if pd.isna(start_string) or pd.isna(end_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    if use_fuzzy:\n",
    "        # Perform fuzzy matching for start_string\n",
    "        start_match = process.extractOne(start_string, note.splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "        if start_match:\n",
    "            start_string = start_match[0]\n",
    "        \n",
    "        # Perform fuzzy matching for end_string\n",
    "        end_match = process.extractOne(end_string, note.splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "        if end_match:\n",
    "            end_string = end_match[0]\n",
    "\n",
    "    if start_string not in note or end_string not in note:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    start_index = note.find(start_string)\n",
    "    end_index = note.find(end_string, start_index) + len(end_string)\n",
    "\n",
    "    if start_index == -1 or end_index == -1 or start_index >= end_index:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    return start_index, end_index\n",
    "\n",
    "# Define a wrapper function for applying the extraction to your DataFrame\n",
    "def benchmark_function():\n",
    "    gt_df['start_pred_fuzzy'], gt_df['end_pred_fuzzy'] = zip(\n",
    "        *gt_df.apply(lambda row: extract_section_from_note_from_row(row, use_fuzzy=True, fuzz_threshold=70), axis=1)\n",
    "    )\n",
    "\n",
    "# Time the execution of 1000 calls to the function\n",
    "execution_time = timeit.timeit(benchmark_function, number=int(n_notes/len(gt_df)))\n",
    "\n",
    "print(f\"Execution time for {n_notes} notes: {execution_time:.2f} seconds\")\n",
    "print(f\"Average processing time per note: {(execution_time / n_notes) * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = 1000000\n",
    "\n",
    "import timeit\n",
    "\n",
    "def extract_section_from_note_from_row_fuzzy(row, use_fuzzy: bool = False, fuzz_threshold: int = 80) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extracts a section from a clinical note given the start and end strings from the same DataFrame row,\n",
    "    with optional fuzzy matching.\n",
    "\n",
    "    :param row: A row from a DataFrame containing 'note_text', 'start', and 'end' columns.\n",
    "    :param use_fuzzy: Boolean flag to enable fuzzy matching.\n",
    "    :param fuzz_threshold: The minimum similarity score for fuzzy matching (0-100).\n",
    "    :return: The extracted section text, or None if the section cannot be found.\n",
    "    \"\"\"\n",
    "    note = row['note']\n",
    "    start_string = row['start_pred_string']\n",
    "    end_string = row['end_pred_string']\n",
    "    \n",
    "    if pd.isna(start_string) or pd.isna(end_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    if use_fuzzy:\n",
    "        # Perform fuzzy matching for start_string\n",
    "        start_match = process.extractOne(start_string, note.splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "        if start_match:\n",
    "            start_string = start_match[0]\n",
    "            start_index = note.find(start_string)\n",
    "        \n",
    "            # Perform fuzzy matching for end_string\n",
    "            end_match = process.extractOne(end_string, note[start_index:].splitlines(), scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "            if end_match:\n",
    "                end_string = end_match[0]\n",
    "\n",
    "    if start_string not in note or end_string not in note:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    start_index = note.find(start_string)\n",
    "    end_index = note.find(end_string, start_index) + len(end_string)\n",
    "\n",
    "    if start_index == -1 or end_index == -1 or start_index >= end_index:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    return start_index, end_index\n",
    "\n",
    "# Define a wrapper function for applying the extraction to your DataFrame\n",
    "def benchmark_function():\n",
    "    gt_df['start_pred_fuzzy'], gt_df['end_pred_fuzzy'] = zip(\n",
    "        *gt_df.apply(lambda row: extract_section_from_note_from_row(row, use_fuzzy=True, fuzz_threshold=70), axis=1)\n",
    "    )\n",
    "\n",
    "# Time the execution of 1000 calls to the function\n",
    "execution_time = timeit.timeit(benchmark_function, number=int(n_notes/len(gt_df)))\n",
    "\n",
    "print(f\"Execution time for {n_notes} notes: {execution_time:.2f} seconds\")\n",
    "print(f\"Average processing time per note: {(execution_time / n_notes) * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = 1000000\n",
    "\n",
    "import timeit\n",
    "\n",
    "def extract_section_from_note_from_row_fuzzy(row, fuzz_threshold: int = 80) -> Optional[tuple]:\n",
    "    \"\"\"\n",
    "    Extracts a section from a clinical note given the start and end strings from the same DataFrame row,\n",
    "    with optional fuzzy matching.\n",
    "\n",
    "    :param row: A row from a DataFrame containing 'note', 'start_pred_string', and 'end_pred_string' columns.\n",
    "    :param use_fuzzy: Boolean flag to enable fuzzy matching.\n",
    "    :param fuzz_threshold: The minimum similarity score for fuzzy matching (0-100).\n",
    "    :return: The start and end index of the extracted section, or (np.nan, np.nan) if the section cannot be found.\n",
    "    \"\"\"\n",
    "    note = row['note']\n",
    "    start_string = row['start_pred_string']\n",
    "    end_string = row['end_pred_string']\n",
    "    \n",
    "    if pd.isna(start_string) or pd.isna(end_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Split note into lines\n",
    "    note_lines = note.splitlines()\n",
    "\n",
    "    # Perform fuzzy matching for start_string\n",
    "    start_match = process.extractOne(start_string, note_lines, scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold)\n",
    "    if start_match:\n",
    "        start_string = start_match[0]\n",
    "        start_index = len(\"\\n\".join(note_lines[:start_match[2]])) + (1 if start_match[2] > 0 else 0)\n",
    "\n",
    "        # Perform fuzzy matching for end_string starting after the matched start line\n",
    "        end_match = process.extractOne(end_string, note_lines[start_match[2]:], scorer=fuzz.partial_ratio, score_cutoff=fuzz_threshold, processor=utils.default_process)\n",
    "        if end_match:\n",
    "            end_string = end_match[0]\n",
    "            end_line_index = start_match[2] + end_match[2]\n",
    "            end_index = len(\"\\n\".join(note_lines[:end_line_index + 1]))\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    if start_index == -1 or end_index == -1 or start_index >= end_index:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    return start_index, end_index\n",
    "\n",
    "# Define a wrapper function for applying the extraction to your DataFrame\n",
    "def benchmark_function():\n",
    "    gt_df['start_pred_fuzzy'], gt_df['end_pred_fuzzy'] = zip(\n",
    "        *gt_df.apply(lambda row: extract_section_from_note_from_row_fuzzy(row, fuzz_threshold=70), axis=1)\n",
    "    )\n",
    "\n",
    "# Time the execution of 1000 calls to the function\n",
    "execution_time = timeit.timeit(benchmark_function, number=int(n_notes/len(gt_df)))\n",
    "\n",
    "print(f\"Execution time for {n_notes} notes: {execution_time:.2f} seconds\")\n",
    "print(f\"Average processing time per note: {(execution_time / n_notes) * 1000:.4f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notesectioning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
